# Wrangle and Analyze Data

This project will illustrate the data wrangling process.  Data is gathered from a variety of sources and in a variety of formats.  The data will be assessed for its quality and tidiness, and then it will be cleaned.  The dataset that is being wrangled is the tweet archive of Twitter user [@dog_rates](https://twitter.com/dog_rates), also known as WeRateDogs.

## Software Needed

Being able to work in a Jupyter Notebook is required.

The following libraries need to be installed and can be installed via conda or pip.
- pandas
- NumPy
- requests
- tweepy
- json

## Key Points

Key points to keep in mind when data wrangling for this project:
- Only original ratings (no retweets) that have images are wanted.
- It is only required to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.
- Cleaning includes mergin individual pieces of data according to the rules of tidy data.
- Tweets beyond August 1st, 2017 do not need to be gathered.

## Project Details

The tasks are as follows:

- Data wrangling, which consists of:
 - Gathering data
 - Assessing data
 - Cleaning data

- Storing, analyzing, and visualizing the wrangled data
- Reporting on 1) data wrangling efforts and 2) data analyses and visualizations